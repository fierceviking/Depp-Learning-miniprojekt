Learning rate: 0.001
Train Epoch: 0, Iteration: 0, Finetune Loss: 0.18551117181777954
Train Epoch: 0, Iteration: 10, Finetune Loss: 0.17450231313705444
Train Epoch: 0, Iteration: 20, Finetune Loss: 0.17467224597930908

Average validation loss: 0.16138623058795928
Learning rate: 0.001
Train Epoch: 1, Iteration: 0, Finetune Loss: 0.1921730786561966
Train Epoch: 1, Iteration: 10, Finetune Loss: 0.14976707100868225
Train Epoch: 1, Iteration: 20, Finetune Loss: 0.1845312863588333

Average validation loss: 0.16383830904960633
Learning rate: 0.001
Train Epoch: 2, Iteration: 0, Finetune Loss: 0.1808840036392212
Train Epoch: 2, Iteration: 10, Finetune Loss: 0.19689257442951202
Train Epoch: 2, Iteration: 20, Finetune Loss: 0.18235713243484497

Average validation loss: 0.1631262093782425
Learning rate: 0.001
Train Epoch: 3, Iteration: 0, Finetune Loss: 0.22975143790245056
Train Epoch: 3, Iteration: 10, Finetune Loss: 0.1717032939195633
Train Epoch: 3, Iteration: 20, Finetune Loss: 0.17767001688480377

Average validation loss: 0.15379399061203003
Learning rate: 0.001
Train Epoch: 4, Iteration: 0, Finetune Loss: 0.1863725334405899
Train Epoch: 4, Iteration: 10, Finetune Loss: 0.1563653200864792
Train Epoch: 4, Iteration: 20, Finetune Loss: 0.16066616773605347

Average validation loss: 0.15528038442134856
Learning rate: 0.001
Train Epoch: 5, Iteration: 0, Finetune Loss: 0.17443391680717468
Train Epoch: 5, Iteration: 10, Finetune Loss: 0.19296298921108246
Train Epoch: 5, Iteration: 20, Finetune Loss: 0.19152426719665527

Average validation loss: 0.1573716312646866
Learning rate: 0.001
Train Epoch: 6, Iteration: 0, Finetune Loss: 0.18759149312973022
Train Epoch: 6, Iteration: 10, Finetune Loss: 0.18031559884548187
Train Epoch: 6, Iteration: 20, Finetune Loss: 0.16330142319202423

Average validation loss: 0.1526320219039917
Learning rate: 0.001
Train Epoch: 7, Iteration: 0, Finetune Loss: 0.18047083914279938
Train Epoch: 7, Iteration: 10, Finetune Loss: 0.17636775970458984
Train Epoch: 7, Iteration: 20, Finetune Loss: 0.17015860974788666

Average validation loss: 0.15949312150478362
Learning rate: 0.001
Train Epoch: 8, Iteration: 0, Finetune Loss: 0.1729893684387207
Train Epoch: 8, Iteration: 10, Finetune Loss: 0.17688186466693878
Train Epoch: 8, Iteration: 20, Finetune Loss: 0.1931816041469574

Average validation loss: 0.16405511796474456
Learning rate: 0.001
Train Epoch: 9, Iteration: 0, Finetune Loss: 0.19578078389167786
Train Epoch: 9, Iteration: 10, Finetune Loss: 0.17689532041549683
Train Epoch: 9, Iteration: 20, Finetune Loss: 0.20045095682144165

Average validation loss: 0.1506376475095749
Learning rate: 0.001
Train Epoch: 10, Iteration: 0, Finetune Loss: 0.19711071252822876
Train Epoch: 10, Iteration: 10, Finetune Loss: 0.1453322321176529
Train Epoch: 10, Iteration: 20, Finetune Loss: 0.18304696679115295

Average validation loss: 0.15763472616672516
Learning rate: 0.001
Train Epoch: 11, Iteration: 0, Finetune Loss: 0.19365987181663513
Train Epoch: 11, Iteration: 10, Finetune Loss: 0.16787616908550262
Train Epoch: 11, Iteration: 20, Finetune Loss: 0.1736462414264679

Average validation loss: 0.15518781244754792
Learning rate: 0.001
Train Epoch: 12, Iteration: 0, Finetune Loss: 0.1756325662136078
Train Epoch: 12, Iteration: 10, Finetune Loss: 0.16631563007831573
Train Epoch: 12, Iteration: 20, Finetune Loss: 0.17442686855793

Average validation loss: 0.16628686487674713
Learning rate: 0.001
Train Epoch: 13, Iteration: 0, Finetune Loss: 0.16888321936130524
Train Epoch: 13, Iteration: 10, Finetune Loss: 0.19172050058841705
Train Epoch: 13, Iteration: 20, Finetune Loss: 0.18533912301063538

Average validation loss: 0.16314389407634736
Learning rate: 0.001
Train Epoch: 14, Iteration: 0, Finetune Loss: 0.1640910804271698
Train Epoch: 14, Iteration: 10, Finetune Loss: 0.172795832157135
Train Epoch: 14, Iteration: 20, Finetune Loss: 0.19209593534469604

Average validation loss: 0.16795919537544252
Learning rate: 0.001
Train Epoch: 15, Iteration: 0, Finetune Loss: 0.141892671585083
Train Epoch: 15, Iteration: 10, Finetune Loss: 0.1704251766204834
Train Epoch: 15, Iteration: 20, Finetune Loss: 0.16668076813220978

Average validation loss: 0.1677922636270523
Learning rate: 0.001
Train Epoch: 16, Iteration: 0, Finetune Loss: 0.19121325016021729
Train Epoch: 16, Iteration: 10, Finetune Loss: 0.22424891591072083
Train Epoch: 16, Iteration: 20, Finetune Loss: 0.20019638538360596

Average validation loss: 0.15558544993400575
Learning rate: 0.001
Train Epoch: 17, Iteration: 0, Finetune Loss: 0.17979326844215393
Train Epoch: 17, Iteration: 10, Finetune Loss: 0.187008336186409
Train Epoch: 17, Iteration: 20, Finetune Loss: 0.14832210540771484

Average validation loss: 0.1520857572555542
Learning rate: 0.001
Train Epoch: 18, Iteration: 0, Finetune Loss: 0.1702195107936859
Train Epoch: 18, Iteration: 10, Finetune Loss: 0.16108070313930511
Train Epoch: 18, Iteration: 20, Finetune Loss: 0.14902856945991516

Average validation loss: 0.1578029900789261
Learning rate: 0.001
Train Epoch: 19, Iteration: 0, Finetune Loss: 0.15895220637321472
Train Epoch: 19, Iteration: 10, Finetune Loss: 0.2105039805173874
Train Epoch: 19, Iteration: 20, Finetune Loss: 0.2176557034254074

Average validation loss: 0.14981406331062316
Learning rate: 0.0005
Train Epoch: 20, Iteration: 0, Finetune Loss: 0.16733454167842865
Train Epoch: 20, Iteration: 10, Finetune Loss: 0.18358728289604187
Train Epoch: 20, Iteration: 20, Finetune Loss: 0.18062730133533478

Average validation loss: 0.15064371526241302
Learning rate: 0.0005
Train Epoch: 21, Iteration: 0, Finetune Loss: 0.17142488062381744
Train Epoch: 21, Iteration: 10, Finetune Loss: 0.1817101389169693
Train Epoch: 21, Iteration: 20, Finetune Loss: 0.178102046251297

Average validation loss: 0.16210074126720428
Learning rate: 0.0005
Train Epoch: 22, Iteration: 0, Finetune Loss: 0.15897098183631897
Train Epoch: 22, Iteration: 10, Finetune Loss: 0.18248531222343445
Train Epoch: 22, Iteration: 20, Finetune Loss: 0.19679784774780273

Average validation loss: 0.1567210227251053
Learning rate: 0.0005
Train Epoch: 23, Iteration: 0, Finetune Loss: 0.18097640573978424
Train Epoch: 23, Iteration: 10, Finetune Loss: 0.16318446397781372
Train Epoch: 23, Iteration: 20, Finetune Loss: 0.20348507165908813

Average validation loss: 0.15663909912109375
Learning rate: 0.0005
Train Epoch: 24, Iteration: 0, Finetune Loss: 0.18096937239170074
Train Epoch: 24, Iteration: 10, Finetune Loss: 0.15902864933013916
Train Epoch: 24, Iteration: 20, Finetune Loss: 0.2056507170200348

Average validation loss: 0.1572473466396332
Learning rate: 0.0005
Train Epoch: 25, Iteration: 0, Finetune Loss: 0.19162964820861816
Train Epoch: 25, Iteration: 10, Finetune Loss: 0.20906595885753632
Train Epoch: 25, Iteration: 20, Finetune Loss: 0.18021778762340546

Average validation loss: 0.16102540493011475
Learning rate: 0.0005
Train Epoch: 26, Iteration: 0, Finetune Loss: 0.1892392933368683
Train Epoch: 26, Iteration: 10, Finetune Loss: 0.18790239095687866
Train Epoch: 26, Iteration: 20, Finetune Loss: 0.17179487645626068

Average validation loss: 0.1558983564376831
Learning rate: 0.0005
Train Epoch: 27, Iteration: 0, Finetune Loss: 0.1642695963382721
Train Epoch: 27, Iteration: 10, Finetune Loss: 0.1810113489627838
Train Epoch: 27, Iteration: 20, Finetune Loss: 0.17299847304821014

Average validation loss: 0.15422093868255615
Learning rate: 0.0005
Train Epoch: 28, Iteration: 0, Finetune Loss: 0.1836361289024353
Train Epoch: 28, Iteration: 10, Finetune Loss: 0.18140161037445068
Train Epoch: 28, Iteration: 20, Finetune Loss: 0.21241989731788635

Average validation loss: 0.15641225278377532
Learning rate: 0.0005
Train Epoch: 29, Iteration: 0, Finetune Loss: 0.19011420011520386
Train Epoch: 29, Iteration: 10, Finetune Loss: 0.16925466060638428
Train Epoch: 29, Iteration: 20, Finetune Loss: 0.18693001568317413

Average validation loss: 0.16128432452678682
Learning rate: 0.0005
Train Epoch: 30, Iteration: 0, Finetune Loss: 0.1834305226802826
Train Epoch: 30, Iteration: 10, Finetune Loss: 0.1710045486688614
Train Epoch: 30, Iteration: 20, Finetune Loss: 0.18874220550060272

Average validation loss: 0.1554586261510849
Learning rate: 0.0005
Train Epoch: 31, Iteration: 0, Finetune Loss: 0.1605570763349533
Train Epoch: 31, Iteration: 10, Finetune Loss: 0.19121044874191284
Train Epoch: 31, Iteration: 20, Finetune Loss: 0.215492382645607

Average validation loss: 0.158621084690094
Learning rate: 0.0005
Train Epoch: 32, Iteration: 0, Finetune Loss: 0.15350601077079773
Train Epoch: 32, Iteration: 10, Finetune Loss: 0.19596317410469055
Train Epoch: 32, Iteration: 20, Finetune Loss: 0.183304101228714

Average validation loss: 0.15147360265254975
Learning rate: 0.0005
Train Epoch: 33, Iteration: 0, Finetune Loss: 0.18958315253257751
Train Epoch: 33, Iteration: 10, Finetune Loss: 0.1742081493139267
Train Epoch: 33, Iteration: 20, Finetune Loss: 0.157497838139534

Average validation loss: 0.15327126979827882
Learning rate: 0.0005
Train Epoch: 34, Iteration: 0, Finetune Loss: 0.18448427319526672
Train Epoch: 34, Iteration: 10, Finetune Loss: 0.16954511404037476
Train Epoch: 34, Iteration: 20, Finetune Loss: 0.15331682562828064

Average validation loss: 0.15706520080566405
Learning rate: 0.0005
Train Epoch: 35, Iteration: 0, Finetune Loss: 0.17063076794147491
Train Epoch: 35, Iteration: 10, Finetune Loss: 0.19802801311016083
Train Epoch: 35, Iteration: 20, Finetune Loss: 0.18944483995437622

Average validation loss: 0.15607790052890777
Learning rate: 0.0005
Train Epoch: 36, Iteration: 0, Finetune Loss: 0.1764107495546341
Train Epoch: 36, Iteration: 10, Finetune Loss: 0.17975813150405884
Train Epoch: 36, Iteration: 20, Finetune Loss: 0.172092467546463

Average validation loss: 0.14874356985092163
Learning rate: 0.0005
Train Epoch: 37, Iteration: 0, Finetune Loss: 0.16380256414413452
Train Epoch: 37, Iteration: 10, Finetune Loss: 0.1637081652879715
Train Epoch: 37, Iteration: 20, Finetune Loss: 0.15363727509975433

Average validation loss: 0.16169992685317994
Learning rate: 0.0005
Train Epoch: 38, Iteration: 0, Finetune Loss: 0.17348386347293854
Train Epoch: 38, Iteration: 10, Finetune Loss: 0.18136216700077057
Train Epoch: 38, Iteration: 20, Finetune Loss: 0.2112937569618225

Average validation loss: 0.152189502120018
Learning rate: 0.0005
Train Epoch: 39, Iteration: 0, Finetune Loss: 0.15430887043476105
Train Epoch: 39, Iteration: 10, Finetune Loss: 0.17241300642490387
Train Epoch: 39, Iteration: 20, Finetune Loss: 0.17712551355361938

Average validation loss: 0.14476471543312072
Learning rate: 0.00025
Train Epoch: 40, Iteration: 0, Finetune Loss: 0.17095822095870972
Train Epoch: 40, Iteration: 10, Finetune Loss: 0.18691767752170563
Train Epoch: 40, Iteration: 20, Finetune Loss: 0.17254135012626648

Average validation loss: 0.1508186310529709
Learning rate: 0.00025
Train Epoch: 41, Iteration: 0, Finetune Loss: 0.1538909375667572
Train Epoch: 41, Iteration: 10, Finetune Loss: 0.17869246006011963
Train Epoch: 41, Iteration: 20, Finetune Loss: 0.17290861904621124

Average validation loss: 0.163923978805542
Learning rate: 0.00025
Train Epoch: 42, Iteration: 0, Finetune Loss: 0.16075152158737183
Train Epoch: 42, Iteration: 10, Finetune Loss: 0.16711880266666412
Train Epoch: 42, Iteration: 20, Finetune Loss: 0.16265413165092468

Average validation loss: 0.15759043991565705
Learning rate: 0.00025
Train Epoch: 43, Iteration: 0, Finetune Loss: 0.17382094264030457
Train Epoch: 43, Iteration: 10, Finetune Loss: 0.18341763317584991
Train Epoch: 43, Iteration: 20, Finetune Loss: 0.20133180916309357

Average validation loss: 0.16173837780952455
Learning rate: 0.00025
Train Epoch: 44, Iteration: 0, Finetune Loss: 0.15063083171844482
Train Epoch: 44, Iteration: 10, Finetune Loss: 0.1580227017402649
Train Epoch: 44, Iteration: 20, Finetune Loss: 0.19129198789596558

Average validation loss: 0.16297526359558107
Learning rate: 0.00025
Train Epoch: 45, Iteration: 0, Finetune Loss: 0.13934670388698578
Train Epoch: 45, Iteration: 10, Finetune Loss: 0.14595413208007812
Train Epoch: 45, Iteration: 20, Finetune Loss: 0.15349525213241577

Average validation loss: 0.14950251281261445
Learning rate: 0.00025
Train Epoch: 46, Iteration: 0, Finetune Loss: 0.19118942320346832
Train Epoch: 46, Iteration: 10, Finetune Loss: 0.15343858301639557
Train Epoch: 46, Iteration: 20, Finetune Loss: 0.18575164675712585

Average validation loss: 0.15252399444580078
Learning rate: 0.00025
Train Epoch: 47, Iteration: 0, Finetune Loss: 0.19357091188430786
Train Epoch: 47, Iteration: 10, Finetune Loss: 0.18761475384235382
Train Epoch: 47, Iteration: 20, Finetune Loss: 0.1831817477941513

Average validation loss: 0.1633894294500351
Learning rate: 0.00025
Train Epoch: 48, Iteration: 0, Finetune Loss: 0.17505909502506256
Train Epoch: 48, Iteration: 10, Finetune Loss: 0.20160333812236786
Train Epoch: 48, Iteration: 20, Finetune Loss: 0.15709979832172394

Average validation loss: 0.15556981563568115
Learning rate: 0.00025
Train Epoch: 49, Iteration: 0, Finetune Loss: 0.19731560349464417
Train Epoch: 49, Iteration: 10, Finetune Loss: 0.1555904746055603
Train Epoch: 49, Iteration: 20, Finetune Loss: 0.20488733053207397

Average validation loss: 0.16131774485111236
Learning rate: 0.00025
Train Epoch: 50, Iteration: 0, Finetune Loss: 0.1569541096687317
Train Epoch: 50, Iteration: 10, Finetune Loss: 0.18474002182483673
Train Epoch: 50, Iteration: 20, Finetune Loss: 0.15964101254940033

Average validation loss: 0.15111212730407714
[1;34mwandb[0m: ðŸš€ View run [33mlemon-forest-41[0m at: [34mhttps://wandb.ai/mpham22-aalborg-university/DL_miniproject/runs/d8qyad3n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241027_121501-d8qyad3n/logs[0m
